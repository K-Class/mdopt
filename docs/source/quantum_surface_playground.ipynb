{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoding Shor's Code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment, we decode Shor's nine-qubit quantum error correcting code which protects a single qubit from all types of errors. Here, we demonstrate error-based correction, which means that the decoder takes a Pauli error as input and outputs the most likely logical operator. After one run of the algorithm we will end up with a probability distribution over I, X, Z, Y Pauli operators which are to be applied to the logical qubit encoded. In this experiment, we do not truncate thus perform exact maximum likelihood decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import qecstruct as qc\n",
    "import qecsim.paulitools as pt\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from mdopt.mps.utils import marginalise, create_custom_product_state\n",
    "from mdopt.contractor.contractor import mps_mpo_contract\n",
    "from mdopt.optimiser.utils import (\n",
    "    SWAP,\n",
    "    COPY_LEFT,\n",
    "    XOR_BULK,\n",
    "    XOR_LEFT,\n",
    "    XOR_RIGHT,\n",
    ")\n",
    "from examples.decoding.decoding import (\n",
    "    css_code_checks,\n",
    "    css_code_logicals,\n",
    "    css_code_logicals_sites,\n",
    "    css_code_constraint_sites,\n",
    ")\n",
    "from examples.decoding.decoding import (\n",
    "    apply_constraints,\n",
    "    apply_bitflip_bias,\n",
    "    apply_depolarising_bias,\n",
    ")\n",
    "from examples.decoding.decoding import (\n",
    "    pauli_to_mps,\n",
    "    decode_css,\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import qecstruct as qc\n",
    "from scipy.stats import sem\n",
    "import qecsim.paulitools as pt\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "from mdopt.mps.utils import marginalise, create_custom_product_state\n",
    "from mdopt.contractor.contractor import mps_mpo_contract\n",
    "from mdopt.optimiser.utils import (\n",
    "    SWAP,\n",
    "    COPY_LEFT,\n",
    "    XOR_BULK,\n",
    "    XOR_LEFT,\n",
    "    XOR_RIGHT,\n",
    ")\n",
    "from examples.decoding.decoding import (\n",
    "    apply_constraints,\n",
    "    apply_bitflip_bias,\n",
    "    css_code_stabilisers,\n",
    "    multiply_pauli_strings,\n",
    ")\n",
    "from examples.decoding.decoding import (\n",
    "    decode_css,\n",
    "    pauli_to_mps,\n",
    "    css_code_checks,\n",
    "    css_code_logicals,\n",
    "    css_code_stabilisers,\n",
    "    css_code_logicals_sites,\n",
    "    css_code_constraint_sites,\n",
    "    generate_pauli_error_string,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first import the code from `qecstruct` and take a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATTICE_SIZE = 3\n",
    "rep_code = qc.repetition_code(LATTICE_SIZE)\n",
    "code = qc.hypergraph_product(rep_code, rep_code)\n",
    "print(code)\n",
    "print(\"The X logical: \", code.x_logicals_binary())\n",
    "print(\"The Z logical: \", code.z_logicals_binary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This quantum error correcting code is defined on $2 * L * (L-1) + 1 = 13$ (where $L$ is the lattice size and an extra qubit handles the boundary conditions) physical qubits and has $2$ logical operators because it encodes $1$ logical qubit. This means we will need $13*2 + 2 = 28$ sites in our MPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_logicals = code.num_x_logicals() + code.num_z_logicals()\n",
    "num_sites = 2 * len(code) + num_logicals\n",
    "\n",
    "assert num_sites == 28\n",
    "assert num_logicals == 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us define the initial state. First of all we will check that no error implies no correction. This means starting from the all-zeros state followed by decoding will return all-zeros state for the logical operators (the final logical operator will thus be identity operator). Thus, we start from the all-zero state for the error and the $|+\\rangle$ state for the logicals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_state = \"0\" * (num_sites - num_logicals)\n",
    "logicals_state = \"+\" * num_logicals\n",
    "state_string = logicals_state + error_state\n",
    "error_mps = create_custom_product_state(string=state_string)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we get the sites where the checks will be applied. We will need to construct MPOs using this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checks_x, checks_z = css_code_checks(code)\n",
    "print(\"X checks:\")\n",
    "for check in checks_x:\n",
    "    print(check)\n",
    "print(\"Z checks:\")\n",
    "for check in checks_z:\n",
    "    print(check)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These lists mention only the sites where we will apply the XOR constraints. However, the MPOs will also consist of other tensors, such as SWAPs (tensors' legs crossings) and boundary XOR constraints. In what follows we define the list of these auxiliary tensors and the corresponding sites where they reside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints_tensors = [XOR_LEFT, XOR_BULK, SWAP, XOR_RIGHT]\n",
    "logicals_tensors = [COPY_LEFT, XOR_BULK, SWAP, XOR_RIGHT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints_sites = css_code_constraint_sites(code)\n",
    "print(\"Full X-check lists of sites:\")\n",
    "for string in constraints_sites[0]:\n",
    "    print(string)\n",
    "print(\"Full Z-check lists of sites:\")\n",
    "for string in constraints_sites[1]:\n",
    "    print(string)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now again take a look at the logical operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(code.x_logicals_binary())\n",
    "print(code.z_logicals_binary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to again translate them to our MPO language by changing the indices since we add the logical sites at the beginning of the MPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(css_code_logicals(code)[0])\n",
    "print(css_code_logicals(code)[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now goes the same operation of adding sites where auxiliary tensors should be placed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logicals_sites = css_code_logicals_sites(code)\n",
    "print(css_code_logicals_sites(code)[0])\n",
    "print(css_code_logicals_sites(code)[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the fun part, MPS-MPO contraction. But first, we apply the bias channel to our error state. This is done to bias our output towards the received input. This is done by distributing the amplitude around the initial basis product state to other basis product states in the descending order by Hamming distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "renormalise = True\n",
    "result_to_explicit = False\n",
    "sites_to_bias = list(range(num_logicals, num_sites))\n",
    "error_mps = apply_bitflip_bias(\n",
    "    mps=error_mps,\n",
    "    sites_to_bias=sites_to_bias,\n",
    "    renormalise=renormalise,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropies, bond_dims = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_mps, entrps, bnd_dims = apply_constraints(\n",
    "    error_mps,\n",
    "    constraints_sites[0],\n",
    "    constraints_tensors,\n",
    "    renormalise=renormalise,\n",
    "    result_to_explicit=result_to_explicit,\n",
    "    strategy=\"Optimised\",\n",
    "    return_entropies_and_bond_dims=True,\n",
    ")\n",
    "entropies += entrps\n",
    "bond_dims += bnd_dims\n",
    "error_mps, entrps, bnd_dims = apply_constraints(\n",
    "    error_mps,\n",
    "    constraints_sites[1],\n",
    "    constraints_tensors,\n",
    "    renormalise=renormalise,\n",
    "    result_to_explicit=result_to_explicit,\n",
    "    strategy=\"Optimised\",\n",
    "    return_entropies_and_bond_dims=True,\n",
    ")\n",
    "entropies += entrps\n",
    "bond_dims += bnd_dims\n",
    "error_mps, entrps, bnd_dims = apply_constraints(\n",
    "    error_mps,\n",
    "    logicals_sites,\n",
    "    logicals_tensors,\n",
    "    renormalise=renormalise,\n",
    "    result_to_explicit=result_to_explicit,\n",
    "    strategy=\"Optimised\",\n",
    "    return_entropies_and_bond_dims=True,\n",
    ")\n",
    "entropies += entrps\n",
    "bond_dims += bnd_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(bond_dims)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(entropies)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we marginalise over the message bits to get the probability distribution over the four possibilities of a logical operator: $I$, $X$, $Z$, $Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites_to_marginalise = list(range(num_logicals, len(error_state) + num_logicals))\n",
    "logical = marginalise(mps=error_mps, sites_to_marginalise=sites_to_marginalise).dense(\n",
    "    flatten=True, renormalise=True, norm=1\n",
    ")\n",
    "print(logical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = \"Optimised\"\n",
    "logical_values = [[] for _ in range(4)]\n",
    "bond_dims = [np.inf, 4096, 2048, 1024] + list(range(512, 2, -8))\n",
    "\n",
    "for max_bond_dim in tqdm(bond_dims):\n",
    "    error_state = \"0\" * (num_sites - num_logicals)\n",
    "    logicals_state = \"+\" * num_logicals\n",
    "    state_string = logicals_state + error_state\n",
    "    error_mps = create_custom_product_state(string=state_string)\n",
    "\n",
    "    error_mps = apply_bitflip_bias(\n",
    "        mps=error_mps,\n",
    "        prob_bias_list=0.01,\n",
    "        sites_to_bias=sites_to_bias,\n",
    "        renormalise=renormalise,\n",
    "    )\n",
    "\n",
    "    error_mps = apply_constraints(\n",
    "        error_mps,\n",
    "        constraints_sites[0],\n",
    "        constraints_tensors,\n",
    "        renormalise=renormalise,\n",
    "        result_to_explicit=result_to_explicit,\n",
    "        strategy=strategy,\n",
    "        chi_max=max_bond_dim,\n",
    "        silent=True,\n",
    "    )\n",
    "    error_mps = apply_constraints(\n",
    "        error_mps,\n",
    "        constraints_sites[1],\n",
    "        constraints_tensors,\n",
    "        renormalise=renormalise,\n",
    "        result_to_explicit=result_to_explicit,\n",
    "        strategy=strategy,\n",
    "        chi_max=max_bond_dim,\n",
    "        silent=True,\n",
    "    )\n",
    "    error_mps = apply_constraints(\n",
    "        error_mps,\n",
    "        logicals_sites,\n",
    "        logicals_tensors,\n",
    "        renormalise=renormalise,\n",
    "        result_to_explicit=result_to_explicit,\n",
    "        strategy=strategy,\n",
    "        chi_max=max_bond_dim,\n",
    "        silent=True,\n",
    "    )\n",
    "\n",
    "    sites_to_marginalise = list(range(num_logicals, len(error_state) + num_logicals))\n",
    "    logical = marginalise(\n",
    "        mps=error_mps, sites_to_marginalise=sites_to_marginalise\n",
    "    ).dense(flatten=True, renormalise=True, norm=1)\n",
    "\n",
    "    for i in range(4):\n",
    "        logical_values[i].append(logical[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(bond_dims, logical_values[0], marker=\"o\", label=f\"Pr(I)\")\n",
    "plt.plot(bond_dims, logical_values[1], marker=\"o\", label=f\"Pr(X)\")\n",
    "plt.plot(bond_dims, logical_values[2], marker=\"o\", label=f\"Pr(Z)\")\n",
    "plt.plot(bond_dims, logical_values[3], marker=\"o\", label=f\"Pr(Y)\")\n",
    "plt.xlabel(\"Max Bond Dimension\")\n",
    "plt.ylabel(\"Logical Value\")\n",
    "plt.title(\"Logical Values vs Bond Dimension (Optimised)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logical_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which indeed tells us that most likely we do not need to apply any operator!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now put all of this into a function. We'll need this to run the decoder over a bunch of single- and multiqubit errors."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now generate all possible one-, two- and three-qubit errors using `qecsim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_qubit_paulis = pt.ipauli(n_qubits=len(code), min_weight=1, max_weight=1)\n",
    "two_qubit_paulis = pt.ipauli(n_qubits=len(code), min_weight=2, max_weight=2)\n",
    "three_qubit_paulis = pt.ipauli(n_qubits=len(code), min_weight=3, max_weight=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_qubit_errors = [pauli_to_mps(pauli) for pauli in one_qubit_paulis]\n",
    "one_qubit_outputs = [\n",
    "    decode_css(code, error, bias_type=\"Bitflip\", renormalise=renormalise, silent=True)\n",
    "    for error in tqdm(one_qubit_errors)\n",
    "]\n",
    "one_qubit_corrections_distribution = [output[0] for output in one_qubit_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_qubit_errors = [pauli_to_mps(pauli) for pauli in two_qubit_paulis]\n",
    "two_qubit_outputs = [\n",
    "    decode_css(code, error, bias_type=\"Bitflip\", renormalise=renormalise, silent=True)\n",
    "    for error in tqdm(two_qubit_errors)\n",
    "]\n",
    "two_qubit_corrections_distribution = [output[0] for output in two_qubit_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_qubit_errors = [pauli_to_mps(pauli) for pauli in three_qubit_paulis]\n",
    "three_qubit_outputs = [\n",
    "    decode_css(code, error, bias_type=\"Bitflip\", renormalise=renormalise, silent=True)\n",
    "    for error in tqdm(three_qubit_errors)\n",
    "]\n",
    "three_qubit_corrections_distribution = [output[0] for output in three_qubit_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_distribution_to_pauli(distribution):\n",
    "    mapping = {0: \"I\", 1: \"X\", 2: \"Z\", 3: \"Y\"}\n",
    "    result = []\n",
    "\n",
    "    for array in distribution:\n",
    "        max_index = np.argmax(array)\n",
    "        result.append(mapping[max_index])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(map_distribution_to_pauli(one_qubit_corrections_distribution))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(map_distribution_to_pauli(two_qubit_corrections_distribution))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(map_distribution_to_pauli(three_qubit_corrections_distribution))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now check by hand that some of the decoder's nontrivial outputs are indeed correct. First of all, from all one-qubit errors we get an Identity operator which corresponds to the fact that Shor's code corrects all one-qubit errors. However, Shor's code can also correct some two-qubit errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_qubit_paulis = list(pt.ipauli(n_qubits=len(code), min_weight=1, max_weight=1))\n",
    "two_qubit_paulis = list(pt.ipauli(n_qubits=len(code), min_weight=2, max_weight=2))\n",
    "three_qubit_paulis = list(pt.ipauli(n_qubits=len(code), min_weight=3, max_weight=3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the first 20 errors which result in the Identity logical operator as the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 20\n",
    "for i, correction in enumerate(\n",
    "    map_distribution_to_pauli(two_qubit_corrections_distribution)\n",
    "):\n",
    "    if correction == \"I\":\n",
    "        print(two_qubit_paulis[i])\n",
    "    if i > limit:\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to dive a bit more into what is happening inside the decoder to be able to better understand the results, even though the current setup is already sufficient for calculating thresholds. For example, the first error $(X_0 X_1)$ from the list above would trigger the first $X$ parity check in the case of measuring it. This can be seen from the actual tensor network we are building (see the image below). However, in the current setup the stabilisers are being set to $0$, which is the result of the fact that the $\\text{XOR}$ tensors we use project out the inputs of odd (i.e., equal to $1$) parity. What happens next after applying the logical-operator MPOs and marginalising basically spits out a marginal distribution over codewords corresponding to different parities of the logical operators.\n",
    "\n",
    "<img src=\"shor-decoder.png\" alt=\"Tensor-network error-based decoder for the Shor's 9-qubit code.\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now take a look at the errors which result in the $X$ logical operator as the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, correction in enumerate(\n",
    "    map_distribution_to_pauli(two_qubit_corrections_distribution)\n",
    "):\n",
    "    if correction == \"X\":\n",
    "        print(two_qubit_paulis[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the previous case, the first error $(Z_0 Z_1)$ from the list above would trigger the first $Z$ parity check which in its turn would trigger the $\\text{XOR}$ tensor corresponding to the $X$ logical-operator MPO therefore the $X$ logical as the most likely output."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdopt-ZdbamFdU-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64c06a7280c9749d5771a76ca6109d7df6b2615ddb3b9b0828f83fb315c7f8a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
